{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils import check_array\n",
    "from tqdm import tqdm\n",
    "import pdb\n",
    "\n",
    "# Get the parent directory of this file\n",
    "current_directory = os.path.dirname(os.path.abspath(__name__))\n",
    "\n",
    "# Get the data directory\n",
    "data_directory = os.path.join(current_directory, 'data')\n",
    "\n",
    "# Get the CSV files\n",
    "csv_files = [f for f in os.listdir(data_directory) if f.endswith('.csv')]\n",
    "\n",
    "# Iterate over each CSV file and merge them by subject_id\n",
    "combined_data = pd.DataFrame()\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(data_directory, file)\n",
    "    data = pd.read_csv(file_path)\n",
    "    combined_data = pd.concat([combined_data, data], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['subject_id', 'hadm_id', 'admittime', 'dischtime', 'deathtime',\n",
       "       'admission_type', 'admission_location', 'discharge_location',\n",
       "       'insurance', 'language', 'marital_status', 'ethnicity', 'edregtime',\n",
       "       'edouttime', 'hospital_expire_flag', 'seq_num', 'chartdate', 'icd_code',\n",
       "       'icd_version', 'gender', 'anchor_age', 'anchor_year',\n",
       "       'anchor_year_group', 'dod'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data.admittime = pd.to_datetime(combined_data.admittime)\n",
    "combined_data.dischtime = pd.to_datetime(combined_data.dischtime)\n",
    "combined_data.deathtime = pd.to_datetime(combined_data.deathtime)\n",
    "\n",
    "# Convert to days\n",
    "combined_data['length_of_stay'] = (combined_data.dischtime - combined_data.admittime).dt.days\n",
    "combined_data.deathtime = (combined_data.deathtime - combined_data.admittime.min()) / np.timedelta64(1, 'D')\n",
    "combined_data.dischtime = (combined_data.dischtime - combined_data.admittime.min()) / np.timedelta64(1, 'D')\n",
    "combined_data.admittime = (combined_data.admittime - combined_data.admittime.min()) / np.timedelta64(1, 'D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          12409.868056\n",
       "1           6577.270833\n",
       "2          15076.648611\n",
       "3          21999.004861\n",
       "4           6171.640278\n",
       "               ...     \n",
       "6965989             NaN\n",
       "6965990             NaN\n",
       "6965991             NaN\n",
       "6965992             NaN\n",
       "6965993             NaN\n",
       "Name: admittime, Length: 6965994, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data.admittime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data.sort_values(by='admittime', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['subject_id', 'hadm_id', 'admittime', 'dischtime', 'deathtime',\n",
       "       'admission_type', 'admission_location', 'discharge_location',\n",
       "       'insurance', 'language', 'marital_status', 'ethnicity', 'edregtime',\n",
       "       'edouttime', 'hospital_expire_flag', 'seq_num', 'chartdate', 'icd_code',\n",
       "       'icd_version', 'gender', 'anchor_age', 'anchor_year',\n",
       "       'anchor_year_group', 'dod', 'length_of_stay'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = combined_data[['admittime', 'ethnicity', 'marital_status', 'insurance', 'language','length_of_stay']]\n",
    "# Cut rows with nan\n",
    "data = data.dropna()\n",
    "data = data[data.ethnicity.isin(['ASIAN', 'WHITE', 'BLACK/AFRICAN AMERICAN', 'HISPANIC OR LATINO'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:06<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "None\n",
      "> \u001b[0;32m/var/folders/nf/9jh22yw56mj181378_s3p7vr0000gn/T/ipykernel_56716/3197773157.py\u001b[0m(71)\u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     68 \u001b[0;31m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./.cache'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     69 \u001b[0;31m\u001b[0;31m#print(X_test.shape, y_test.shape, yhats.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     70 \u001b[0;31m\u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumn_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myhats\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'prediction'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 71 \u001b[0;31m\u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     72 \u001b[0;31m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\u001b[0m\u001b[0;34m./.cache/\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mregressor\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m.pkl\u001b[0m\u001b[0;34m\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "           admittime               ethnicity marital_status insurance  \\\n",
      "0        1426.454167                   WHITE         SINGLE     Other   \n",
      "1           1532.225                   WHITE        MARRIED     Other   \n",
      "2        1559.608333                   WHITE         SINGLE     Other   \n",
      "3             1559.7                   WHITE       DIVORCED     Other   \n",
      "4        1560.105556                   WHITE       DIVORCED     Other   \n",
      "...              ...                     ...            ...       ...   \n",
      "400329  38774.234028  BLACK/AFRICAN AMERICAN         SINGLE  Medicare   \n",
      "400330  38815.264583                   WHITE        WIDOWED     Other   \n",
      "400331  38821.928472                   WHITE        MARRIED  Medicare   \n",
      "400332  38830.779167                   WHITE        MARRIED  Medicare   \n",
      "400333  38899.782639                   WHITE        MARRIED  Medicare   \n",
      "\n",
      "       language target prediction  \n",
      "0       ENGLISH    0.0        0.0  \n",
      "1       ENGLISH   31.0        0.0  \n",
      "2       ENGLISH    1.0        0.0  \n",
      "3       ENGLISH    4.0        0.0  \n",
      "4       ENGLISH    5.0        0.0  \n",
      "...         ...    ...        ...  \n",
      "400329  ENGLISH    6.0   3.341711  \n",
      "400330  ENGLISH    4.0   4.737115  \n",
      "400331  ENGLISH    4.0    4.09089  \n",
      "400332  ENGLISH    4.0    4.09089  \n",
      "400333  ENGLISH    6.0    4.09089  \n",
      "\n",
      "[400334 rows x 7 columns]\n",
      "0          1426.454167\n",
      "1             1532.225\n",
      "2          1559.608333\n",
      "3               1559.7\n",
      "4          1560.105556\n",
      "              ...     \n",
      "400329    38774.234028\n",
      "400330    38815.264583\n",
      "400331    38821.928472\n",
      "400332    38830.779167\n",
      "400333    38899.782639\n",
      "Name: admittime, Length: 400334, dtype: object\n",
      "0          1426.454167\n",
      "1             1532.225\n",
      "2          1559.608333\n",
      "3               1559.7\n",
      "4          1560.105556\n",
      "              ...     \n",
      "400329    38774.234028\n",
      "400330    38815.264583\n",
      "400331    38821.928472\n",
      "400332    38830.779167\n",
      "400333    38899.782639\n",
      "Name: admittime, Length: 400334, dtype: object\n",
      "0          1426.454167\n",
      "1             1532.225\n",
      "2          1559.608333\n",
      "3               1559.7\n",
      "4          1560.105556\n",
      "              ...     \n",
      "400329    38774.234028\n",
      "400330    38815.264583\n",
      "400331    38821.928472\n",
      "400332    38830.779167\n",
      "400333    38899.782639\n",
      "Name: admittime, Length: 400334, dtype: object\n",
      "           admittime               ethnicity marital_status insurance  \\\n",
      "14588    1426.454167                   WHITE         SINGLE     Other   \n",
      "503485   1532.225000                   WHITE        MARRIED     Other   \n",
      "405361   1559.608333                   WHITE         SINGLE     Other   \n",
      "301650   1559.700000                   WHITE       DIVORCED     Other   \n",
      "424166   1560.105556                   WHITE       DIVORCED     Other   \n",
      "...              ...                     ...            ...       ...   \n",
      "37662   38774.234028  BLACK/AFRICAN AMERICAN         SINGLE  Medicare   \n",
      "252723  38815.264583                   WHITE        WIDOWED     Other   \n",
      "422069  38821.928472                   WHITE        MARRIED  Medicare   \n",
      "419519  38830.779167                   WHITE        MARRIED  Medicare   \n",
      "438611  38899.782639                   WHITE        MARRIED  Medicare   \n",
      "\n",
      "       language  length_of_stay  \n",
      "14588   ENGLISH             0.0  \n",
      "503485  ENGLISH            31.0  \n",
      "405361  ENGLISH             1.0  \n",
      "301650  ENGLISH             4.0  \n",
      "424166  ENGLISH             5.0  \n",
      "...         ...             ...  \n",
      "37662   ENGLISH             6.0  \n",
      "252723  ENGLISH             4.0  \n",
      "422069  ENGLISH             4.0  \n",
      "419519  ENGLISH             4.0  \n",
      "438611  ENGLISH             6.0  \n",
      "\n",
      "[400334 rows x 6 columns]\n",
      "14588      1426.454167\n",
      "503485     1532.225000\n",
      "405361     1559.608333\n",
      "301650     1559.700000\n",
      "424166     1560.105556\n",
      "              ...     \n",
      "37662     38774.234028\n",
      "252723    38815.264583\n",
      "422069    38821.928472\n",
      "419519    38830.779167\n",
      "438611    38899.782639\n",
      "Name: admittime, Length: 400334, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "regressor = \"gradient_boosting\"\n",
    "if regressor == \"gradient_boosting\":\n",
    "    regressor_function = HistGradientBoostingRegressor(max_depth=5)\n",
    "elif regressor == \"logistic_regression\":\n",
    "    regressor_function = LogisticRegression(max_iter=10)\n",
    "else:\n",
    "    raise ValueError(f\"Invalid regrssor: {regressor}\")\n",
    "\n",
    "columns = data.columns\n",
    "\n",
    "# Separate features and target\n",
    "X_test = data.drop('length_of_stay', axis=1)\n",
    "y_test = data['length_of_stay']\n",
    "\n",
    "# Identify numeric and categorical columns\n",
    "numeric_features = X_test.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X_test.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Fit the encoder to all possible categories\n",
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "encoder.fit(X_test[categorical_features])\n",
    "\n",
    "# Create transformers for numeric and categorical data\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', encoder)])\n",
    "\n",
    "# Combine transformers into a preprocessor with ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)],\n",
    "        remainder='passthrough')\n",
    "\n",
    "# Choose regressor\n",
    "\n",
    "# Create a pipeline with preprocessor and a regressor\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', regressor_function)])\n",
    "\n",
    "# Split data into train and test sets\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Fine-tune the model online using a growing dataset\n",
    "yhats = []\n",
    "idxs = [ len(X_test) // 12 * i for i in range(12) ]\n",
    "idxs = idxs[1:]\n",
    "idxs[-1] = len(X_test)\n",
    "\n",
    "for i in tqdm(range(10)):\n",
    "    idx = idxs[i]\n",
    "    _X_train = X_test[:idx]\n",
    "    _y_train = y_test[:idx]\n",
    "    \n",
    "    model.fit(_X_train, _y_train)\n",
    "    yhats.append(model.predict(X_test[idx:idxs[i+1]]))\n",
    "    \n",
    "yhats = np.concatenate(yhats)\n",
    "# Fill in zeros for the first batch of predictions\n",
    "yhats = np.concatenate([np.zeros(len(X_test) - len(yhats)), yhats])\n",
    "\n",
    "# Save the X_test, y_test, y_predict_proba as a dataframe, with the original columns plus 'target' and 'prediction' columns\n",
    "os.makedirs('./.cache', exist_ok=True)\n",
    "#print(X_test.shape, y_test.shape, yhats.shape)\n",
    "df = pd.DataFrame(np.column_stack([X_test, y_test, yhats]), columns=list(X_test.columns) + ['target', 'prediction'])\n",
    "df.to_pickle(f\"./.cache/{regressor}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
